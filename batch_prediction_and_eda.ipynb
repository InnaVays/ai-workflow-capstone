{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Prediction and EDA\n",
    "''' \n",
    "This notebook performs batch predictions using the FastAPI model API and then conducts exploratory data analysis (EDA) \n",
    "on the predictions.\n",
    "'''\n",
    "## Imports and Setup\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define API endpoints\n",
    "TRAIN_API_URL = \"http://localhost:8000/train\"\n",
    "PREDICT_API_URL = \"http://localhost:8000/predict\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send training request to the API\n",
    "def train_models():\n",
    "    data = {\n",
    "        \"data_dir\": \"data/cs-train\",\n",
    "        \"test\": False\n",
    "    }\n",
    "    response = requests.post(TRAIN_API_URL, json=data)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Training completed successfully.\")\n",
    "    else:\n",
    "        print(f\"Training failed: {response.content}\")\n",
    "\n",
    "# Train the models\n",
    "train_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(\"data\",\"cs-production\")\n",
    "\n",
    "# Function to check if a date is within the training data range\n",
    "def is_date_in_range(date_str, start_date, end_date):\n",
    "    date = pd.to_datetime(date_str)\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "    return start <= date <= end\n",
    "\n",
    "# Function to send prediction requests to the API\n",
    "def get_predictions(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        invoices = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for invoice in invoices:\n",
    "        date_str = f\"{invoice['year']}-{invoice['month']}-{invoice['day']}\"\n",
    "        \n",
    "        data = {\n",
    "            \"country\": invoice['country'],\n",
    "            \"year\": invoice['year'],\n",
    "            \"month\": invoice['month'],\n",
    "            \"day\": invoice['day'],\n",
    "            \"test\": False\n",
    "        }\n",
    "        response = requests.post(PREDICT_API_URL, json=data)\n",
    "        if response.status_code == 200:\n",
    "            prediction = response.json()\n",
    "            prediction['invoice'] = invoice['invoice']\n",
    "            prediction['country'] = invoice['country']\n",
    "            prediction['total_price'] = invoice['total_price']\n",
    "            prediction['date'] = date_str\n",
    "            results.append(prediction)\n",
    "        else:\n",
    "            print(f\"Failed to get prediction for invoice {invoice['invoice']}: {response.content}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Path to the prediction data folder\n",
    "data_dir = \"data/cs-production\"\n",
    "\n",
    "# Collect all JSON files in the production data directory\n",
    "json_files = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.endswith('.json')]\n",
    "\n",
    "# Get predictions for all files\n",
    "all_predictions = []\n",
    "for file in json_files:\n",
    "    predictions = get_predictions(file)\n",
    "    all_predictions.extend(predictions)\n",
    "\n",
    "# Save the predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(all_predictions)\n",
    "predictions_df.to_csv(\"batch_predictions.csv\", index=False)\n",
    "\n",
    "# Display the predictions DataFrame\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions data\n",
    "predictions_df = pd.read_csv(\"batch_predictions.csv\")\n",
    "\n",
    "revenue_by_country = predictions_df[['country', 'total_price']].groupby('country').sum().sort_values('price', ascending=False)\n",
    "revenue_by_country = revenue_by_country.rename(columns={'price': 'revenue'})\n",
    "revenue_by_country = revenue_by_country.reset_index()\n",
    "revenue_by_country.head()\n",
    "\n",
    "# Display basic statistics\n",
    "predictions_df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distrebution of price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(predictions_df['price'], bins=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='country', y='revenue', data=revenue_by_country[:5], kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "predictions_df.groupby('country')['y_pred'].mean().plot(kind='bar')\n",
    "plt.title('Average Predictions by Country')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Average Prediction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions over time\n",
    "predictions_df['date'] = pd.to_datetime(predictions_df['date'])\n",
    "plt.figure(figsize=(12, 6))\n",
    "predictions_df.groupby('date')['y_pred'].mean().plot()\n",
    "plt.title('Predictions Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of Predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(predictions_df['y_pred'], bins=30, kde=True)\n",
    "plt.title('Distribution of Predictions')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "correlation_matrix = predictions_df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Notebook to HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the notebook to an HTML report\n",
    "!jupyter nbconvert batch_prediction_and_eda.ipynb --to slides --no-input --post serve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
